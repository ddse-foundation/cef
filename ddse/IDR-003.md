# IDR-003: Enhanced Hybrid Retrieval Implementation

**Status:** Proposed  
**Date:** 2024-11-27  
**Authors:** CEF Project Team  
**Implements:** ADR-002 (Hybrid Retrieval Enhancements)  
**Estimated Duration:** 4-6 weeks

---

## Overview

This document outlines the implementation plan for enhancing the existing hybrid retrieval system to support multi-hop graph reasoning with structured patterns and constraint filtering. **No new interfaces** are introduced - all enhancements are within the existing `KnowledgeRetriever` framework.

---

## Goals

1. **Improve multi-hop support** - Handle 3-8 hop queries that current system struggles with
2. **Add structured patterns** - Support GraphPattern, TraversalStep, Constraint DTOs
3. **Enable constraint filtering** - Apply filters during traversal, not after
4. **Support pattern combinations** - AND/OR/SEQUENTIAL query combinations
5. **Better relation hint usage** - Use ALL hints from GraphQuery, not just first
6. **Maintain backward compatibility** - Existing queries continue to work

---

## Non-Goals

- Creating new service interfaces (PathExecutor, etc.)
- Replacing the hybrid approach
- Breaking existing API contracts
- Major architectural redesign

---

## Implementation Phases

### Phase 1: Add New DTOs (Week 1)

#### 1.1 GraphPattern Record

**File:** `src/main/java/org/ddse/ml/cef/dto/GraphPattern.java`

```java
package org.ddse.ml.cef.dto;

import java.util.List;

/**
 * Structured graph pattern for multi-hop traversal.
 * Used within GraphQuery for the enhanced hybrid retrieval.
 */
public record GraphPattern(
    String patternId,
    List<TraversalStep> steps,
    List<Constraint> constraints,
    String description
) {
    // Factory methods for common patterns
    public static GraphPattern singleHop(String sourceLabel, String relationType, String targetLabel) {
        return new GraphPattern(
            "single_hop",
            List.of(new TraversalStep(sourceLabel, relationType, targetLabel, 0)),
            List.of(),
            "Single hop traversal"
        );
    }
}
```

#### 1.2 TraversalStep Record

**File:** `src/main/java/org/ddse/ml/cef/dto/TraversalStep.java`

```java
package org.ddse.ml.cef.dto;

/**
 * Single step in graph traversal pattern.
 */
public record TraversalStep(
    String sourceLabel,      // null = use previous step result
    String relationType,
    String targetLabel,
    int stepIndex,
    Direction direction
) {
    public TraversalStep(String sourceLabel, String relationType, String targetLabel, int stepIndex) {
        this(sourceLabel, relationType, targetLabel, stepIndex, Direction.OUTGOING);
    }
    
    public enum Direction {
        OUTGOING,
        INCOMING,
        BOTH
    }
}
```

#### 1.3 Constraint Record

**File:** `src/main/java/org/ddse/ml/cef/dto/Constraint.java`

```java
package org.ddse.ml.cef.dto;

import java.util.List;

/**
 * Constraint to apply during graph traversal.
 */
public record Constraint(
    ConstraintType type,
    String nodeLabel,
    String propertyPath,
    Object value,
    int atStep
) {
    public static Constraint propertyEquals(String label, String property, Object value, int step) {
        return new Constraint(ConstraintType.PROPERTY_EQUALS, label, property, value, step);
    }
    
    public static Constraint propertyIn(String label, String property, List<?> values, int step) {
        return new Constraint(ConstraintType.PROPERTY_IN, label, property, values, step);
    }
    
    public static Constraint notIn(String label, String property, List<?> excludeValues, int step) {
        return new Constraint(ConstraintType.NOT_IN, label, property, excludeValues, step);
    }
}

public enum ConstraintType {
    PROPERTY_EQUALS,
    PROPERTY_IN,
    NOT_IN,
    GREATER_THAN,
    LESS_THAN,
    GREATER_THAN_EQUALS,
    LESS_THAN_EQUALS,
    CONTAINS,
    STARTS_WITH,
    ENDS_WITH,
    REGEX_MATCH
}
```

#### 1.4 QueryCombinator Record

**File:** `src/main/java/org/ddse/ml/cef/dto/QueryCombinator.java`

```java
package org.ddse.ml.cef.dto;

import java.util.List;

/**
 * Combine multiple graph patterns with logical operators.
 */
public record QueryCombinator(
    CombinatorType type,
    List<GraphPattern> patterns,
    String description
) {
    public enum CombinatorType {
        INTERSECTION,  // AND - all patterns must match
        UNION,         // OR - any pattern matches
        SEQUENTIAL     // Execute in order, feed results forward
    }
}
```

#### 1.5 MatchedPath Record

**File:** `src/main/java/org/ddse/ml/cef/dto/MatchedPath.java`

```java
package org.ddse.ml.cef.dto;

import java.util.List;
import java.util.Map;
import java.util.UUID;

/**
 * Result of executing a graph pattern.
 * Contains the specific path found, not just a subgraph dump.
 */
public record MatchedPath(
    String patternId,
    List<UUID> nodeIds,
    List<String> relationTypes,
    Map<String, Object> pathProperties,
    double score,
    String explanation
) {
    public UUID getNodeAtStep(int step) {
        return nodeIds.get(step);
    }
    
    public String toPathString() {
        StringBuilder sb = new StringBuilder();
        for (int i = 0; i < nodeIds.size(); i++) {
            sb.append(nodeIds.get(i));
            if (i < relationTypes.size()) {
                sb.append(" →[").append(relationTypes.get(i)).append("]→ ");
            }
        }
        return sb.toString();
    }
}
```

#### 1.6 RankingStrategy Enum

**File:** `src/main/java/org/ddse/ml/cef/dto/RankingStrategy.java`

```java
package org.ddse.ml.cef.dto;

/**
 * Strategy for ranking matched paths.
 */
public enum RankingStrategy {
    PATH_LENGTH,          // Prefer shorter paths
    EDGE_WEIGHT,          // Sum edge weights
    NODE_CENTRALITY,      // Prefer paths through high-centrality nodes
    SEMANTIC_SCORE,       // Combine with vector similarity
    HYBRID                // Weighted combination
}
```

**Deliverables:**
- [ ] 6 new DTO files created
- [ ] Unit tests for DTO validation
- [ ] Documentation with examples

---

### Phase 2: Update Existing DTOs (Week 1-2)

#### 2.1 Enhance GraphQuery

**File:** `src/main/java/org/ddse/ml/cef/dto/GraphQuery.java`

Add new fields:
```java
// Existing fields remain
List<ResolutionTarget> targets;
TraversalHint traversal;

// NEW fields
List<GraphPattern> patterns;
QueryCombinator combinator;
RankingStrategy rankingStrategy;
int maxPaths;

// Helper methods
public boolean hasPatterns() {
    return patterns != null && !patterns.isEmpty();
}

public boolean hasCombinator() {
    return combinator != null && combinator.patterns() != null && 
           !combinator.patterns().isEmpty();
}
```

#### 2.2 Enhance ReasoningContext

**File:** `src/main/java/org/ddse/ml/cef/dto/ReasoningContext.java`

Add:
```java
// NEW field
List<MatchedPath> matchedPaths;

// Helper method
public boolean hasMatchedPaths() {
    return matchedPaths != null && !matchedPaths.isEmpty();
}
```

**Deliverables:**
- [ ] GraphQuery updated with backward compatibility
- [ ] ReasoningContext updated
- [ ] Migration guide for existing usages
- [ ] Unit tests updated

---

### Phase 3: Pattern Execution Logic (Week 2-3)

#### 3.1 Create PatternExecutor Utility Class

**File:** `src/main/java/org/ddse/ml/cef/service/PatternExecutor.java`

Internal utility class (not a service interface) used by `KnowledgeRetrieverImpl`:

```java
@Component
class PatternExecutor {
    
    private final InMemoryKnowledgeGraph graph;
    private final ConstraintEvaluator constraintEvaluator;
    
    /**
     * Execute single pattern starting from entry points.
     */
    List<MatchedPath> executePattern(
        GraphPattern pattern,
        Set<UUID> entryPoints,
        int maxPaths,
        RankingStrategy rankingStrategy
    ) {
        List<MatchedPath> matchedPaths = new ArrayList<>();
        
        for (UUID entryPoint : entryPoints) {
            // Execute step-by-step traversal
            List<PathState> paths = traverseSteps(entryPoint, pattern.steps(), pattern.constraints());
            
            // Convert to MatchedPath and score
            for (PathState path : paths) {
                double score = scorePath(path, rankingStrategy);
                matchedPaths.add(new MatchedPath(
                    pattern.patternId(),
                    path.nodeIds(),
                    path.relationTypes(),
                    path.properties(),
                    score,
                    "Matched pattern: " + pattern.description()
                ));
            }
            
            if (matchedPaths.size() >= maxPaths) break;
        }
        
        // Sort by score and return top maxPaths
        return matchedPaths.stream()
            .sorted(Comparator.comparingDouble(MatchedPath::score).reversed())
            .limit(maxPaths)
            .toList();
    }
    
    /**
     * Step-by-step traversal with constraint filtering.
     */
    private List<PathState> traverseSteps(
        UUID startNode,
        List<TraversalStep> steps,
        List<Constraint> constraints
    ) {
        List<PathState> currentPaths = List.of(new PathState(List.of(startNode), List.of()));
        
        for (int i = 0; i < steps.size(); i++) {
            TraversalStep step = steps.get(i);
            List<PathState> nextPaths = new ArrayList<>();
            
            for (PathState path : currentPaths) {
                UUID currentNode = path.nodeIds().get(path.nodeIds().size() - 1);
                
                // Get neighbors via this relation type
                List<Edge> edges = getEdges(currentNode, step.relationType(), step.direction());
                
                for (Edge edge : edges) {
                    UUID nextNode = edge.getTargetNodeId();
                    Node node = graph.findNode(nextNode).orElse(null);
                    
                    if (node == null) continue;
                    
                    // Check label matches
                    if (step.targetLabel() != null && !step.targetLabel().equals(node.getLabel())) {
                        continue;
                    }
                    
                    // Apply constraints for this step
                    if (!constraintEvaluator.evaluate(node, constraints, i)) {
                        continue;
                    }
                    
                    // Valid path - add to next
                    List<UUID> newNodeIds = new ArrayList<>(path.nodeIds());
                    newNodeIds.add(nextNode);
                    
                    List<String> newRelations = new ArrayList<>(path.relationTypes());
                    newRelations.add(step.relationType());
                    
                    nextPaths.add(new PathState(newNodeIds, newRelations));
                }
            }
            
            currentPaths = nextPaths;
            if (currentPaths.isEmpty()) break; // No valid paths
        }
        
        return currentPaths;
    }
    
    private record PathState(List<UUID> nodeIds, List<String> relationTypes) {
        Map<String, Object> properties() {
            // Aggregate properties along path if needed
            return Map.of();
        }
    }
}
```

#### 3.2 Create ConstraintEvaluator

**File:** `src/main/java/org/ddse/ml/cef/service/ConstraintEvaluator.java`

```java
@Component
class ConstraintEvaluator {
    
    /**
     * Evaluate constraints on a node at given step.
     */
    public boolean evaluate(Node node, List<Constraint> constraints, int currentStep) {
        for (Constraint constraint : constraints) {
            // Skip if constraint is for different step
            if (constraint.atStep() != -1 && constraint.atStep() != currentStep) {
                continue;
            }
            
            // Skip if constraint is for different label
            if (constraint.nodeLabel() != null && !constraint.nodeLabel().equals(node.getLabel())) {
                continue;
            }
            
            // Evaluate constraint
            if (!evaluateSingle(node, constraint)) {
                return false; // Constraint failed
            }
        }
        
        return true; // All constraints passed
    }
    
    private boolean evaluateSingle(Node node, Constraint constraint) {
        Object propertyValue = getProperty(node, constraint.propertyPath());
        
        return switch (constraint.type()) {
            case PROPERTY_EQUALS -> Objects.equals(propertyValue, constraint.value());
            case PROPERTY_IN -> ((List<?>) constraint.value()).contains(propertyValue);
            case NOT_IN -> !((List<?>) constraint.value()).contains(propertyValue);
            case GREATER_THAN -> compareNumbers(propertyValue, constraint.value()) > 0;
            case LESS_THAN -> compareNumbers(propertyValue, constraint.value()) < 0;
            // ... other types
        };
    }
    
    private Object getProperty(Node node, String propertyPath) {
        // Navigate property path (e.g., "properties.name")
        String[] parts = propertyPath.split("\\.");
        Object current = node;
        
        for (String part : parts) {
            if (current instanceof Node n) {
                current = n.getProperties().get(part);
            } else if (current instanceof Map map) {
                current = map.get(part);
            } else {
                return null;
            }
        }
        
        return current;
    }
}
```

**Deliverables:**
- [ ] PatternExecutor utility class
- [ ] ConstraintEvaluator utility class
- [ ] Unit tests for traversal logic
- [ ] Unit tests for constraint evaluation

---

### Phase 4: Enhance KnowledgeRetrieverImpl (Week 3-4)

#### 4.1 Add Pattern Processing

**File:** `src/main/java/org/ddse/ml/cef/service/KnowledgeRetrieverImpl.java`

Update `retrieve()` method:

```java
@Override
public SearchResult retrieve(GraphQuery query) {
    long start = System.currentTimeMillis();
    
    // Check if patterns provided
    if (query.hasPatterns() || query.hasCombinator()) {
        return retrieveWithPatterns(query, start);
    }
    
    // Legacy path: targets + traversal
    return retrieveWithTargets(query, start);
}

private SearchResult retrieveWithPatterns(GraphQuery query, long start) {
    // 1. Determine entry points
    Set<UUID> entryPoints = resolveEntryPointsForPatterns(query);
    
    // 2. Execute patterns
    List<MatchedPath> allMatchedPaths = new ArrayList<>();
    
    if (query.hasCombinator()) {
        // Multi-pattern with combination
        allMatchedPaths = executeCombinator(query.combinator(), entryPoints, query);
    } else {
        // Single or multiple independent patterns
        for (GraphPattern pattern : query.patterns()) {
            List<MatchedPath> paths = patternExecutor.executePattern(
                pattern,
                entryPoints,
                query.maxPaths(),
                query.rankingStrategy()
            );
            allMatchedPaths.addAll(paths);
        }
    }
    
    // 3. Extract nodes from matched paths
    Set<UUID> matchedNodeIds = allMatchedPaths.stream()
        .flatMap(p -> p.nodeIds().stream())
        .collect(Collectors.toSet());
    
    // 4. Get chunks linked to these nodes
    List<UUID> chunkIds = chunkStore.findChunksLinkedToNodes(matchedNodeIds);
    
    // 5. Vector search on those chunks
    List<RankedChunk> rankedChunks = vectorSearchOnChunks(
        query.naturalLanguageQuery(),
        chunkIds,
        query.topK()
    );
    
    // 6. Build reasoning context with matched paths
    ReasoningContext context = new ReasoningContext(
        null, // rootNode
        new ArrayList<>(matchedNodeIds.stream().map(graph::findNode).filter(Optional::isPresent).map(Optional::get).toList()),
        List.of(),
        allMatchedPaths, // NEW: Include matched paths
        extractKeywords(allMatchedPaths),
        Map.of(),
        query.patterns().stream().mapToInt(p -> p.steps().size()).max().orElse(0),
        Map.of()
    );
    
    return new SearchResult(
        rankedChunks,
        SearchStrategy.HYBRID,
        context,
        query.naturalLanguageQuery(),
        System.currentTimeMillis() - start,
        Map.of("matchedPaths", allMatchedPaths.size())
    );
}

private List<MatchedPath> executeCombinator(
    QueryCombinator combinator,
    Set<UUID> entryPoints,
    GraphQuery query
) {
    return switch (combinator.type()) {
        case INTERSECTION -> executeIntersection(combinator, entryPoints, query);
        case UNION -> executeUnion(combinator, entryPoints, query);
        case SEQUENTIAL -> executeSequential(combinator, entryPoints, query);
    };
}

private List<MatchedPath> executeIntersection(
    QueryCombinator combinator,
    Set<UUID> entryPoints,
    GraphQuery query
) {
    // Execute each pattern
    List<Set<UUID>> resultSets = new ArrayList<>();
    
    for (GraphPattern pattern : combinator.patterns()) {
        List<MatchedPath> paths = patternExecutor.executePattern(
            pattern,
            entryPoints,
            query.maxPaths(),
            query.rankingStrategy()
        );
        
        // Extract end nodes from paths
        Set<UUID> endNodes = paths.stream()
            .map(p -> p.nodeIds().get(p.nodeIds().size() - 1))
            .collect(Collectors.toSet());
        
        resultSets.add(endNodes);
    }
    
    // Find intersection
    Set<UUID> intersection = resultSets.get(0);
    for (int i = 1; i < resultSets.size(); i++) {
        intersection.retainAll(resultSets.get(i));
    }
    
    // Re-execute patterns but only keep paths ending in intersection
    List<MatchedPath> filteredPaths = new ArrayList<>();
    for (GraphPattern pattern : combinator.patterns()) {
        List<MatchedPath> paths = patternExecutor.executePattern(
            pattern,
            entryPoints,
            query.maxPaths(),
            query.rankingStrategy()
        );
        
        for (MatchedPath path : paths) {
            UUID endNode = path.nodeIds().get(path.nodeIds().size() - 1);
            if (intersection.contains(endNode)) {
                filteredPaths.add(path);
            }
        }
    }
    
    return filteredPaths;
}
```

**Deliverables:**
- [ ] KnowledgeRetrieverImpl enhanced with pattern support
- [ ] Backward compatibility maintained
- [ ] Integration tests with patterns
- [ ] Integration tests with combinators

---

### Phase 5: Update McpContextTool Schema (Week 4)

#### 5.1 Update Tool Schema

**File:** `src/main/java/org/ddse/ml/cef/mcp/McpContextTool.java`

Update schema generation to include pattern examples:

```java
private String buildToolDescription() {
    return """
        Retrieve relevant knowledge using graph reasoning + semantic search.
        
        For multi-hop queries (3+ hops), use GraphPattern with TraversalSteps:
        
        Example 1 - Multi-hop contraindication (3-hop):
        {
          "textQuery": "Find patients with indirect medication contraindications",
          "graphQuery": {
            "patterns": [{
              "patternId": "multi_hop_contra",
              "steps": [
                {"sourceLabel": "Patient", "relationType": "HAS_CONDITION", "targetLabel": "Condition", "stepIndex": 0},
                {"sourceLabel": "Condition", "relationType": "DIAGNOSED_IN", "targetLabel": "Patient", "stepIndex": 1},
                {"sourceLabel": "Patient", "relationType": "TAKES_MEDICATION", "targetLabel": "Medication", "stepIndex": 2}
              ],
              "constraints": [
                {"type": "PROPERTY_IN", "nodeLabel": "Medication", "propertyPath": "name", "value": ["Methotrexate"], "atStep": 2}
              ]
            }]
          }
        }
        
        Example 2 - Polypharmacy risk (5-condition intersection):
        {
          "textQuery": "Find patients matching all 5 risk criteria",
          "graphQuery": {
            "combinator": {
              "type": "INTERSECTION",
              "patterns": [
                {/* pattern 1: has RA */},
                {/* pattern 2: takes Albuterol */},
                {/* pattern 3: has diabetes */},
                {/* pattern 4: shared doctor */},
                {/* pattern 5: abnormal labs */}
              ]
            }
          }
        }
        
        Schema: %s
        """.formatted(schemaRegistry.getFormattedSchema());
}
```

**Deliverables:**
- [ ] McpContextTool schema updated
- [ ] LLM guidance examples added
- [ ] Integration test with vLLM
- [ ] Documentation updated

---

### Phase 6: Configuration & Properties (Week 4)

#### 6.1 Add Configuration

**File:** `src/main/resources/application.yml`

```yaml
cef:
  search:
    patterns:
      enabled: true
      max-paths: 100
      default-ranking: HYBRID
      constraint-evaluation: strict
      use-all-relation-hints: true
```

**File:** `src/main/java/org/ddse/ml/cef/config/CefProperties.java`

```java
@ConfigurationProperties(prefix = "cef")
public class CefProperties {
    private Search search = new Search();
    
    public static class Search {
        private Patterns patterns = new Patterns();
        
        public static class Patterns {
            private boolean enabled = true;
            private int maxPaths = 100;
            private String defaultRanking = "HYBRID";
            private String constraintEvaluation = "strict";
            private boolean useAllRelationHints = true;
            
            // getters/setters
        }
    }
}
```

**Deliverables:**
- [ ] Configuration properties added
- [ ] Default values set
- [ ] Configuration validation
- [ ] Documentation

---

### Phase 7: Update Benchmarks (Week 5)

#### 7.1 Convert Benchmarks to Use Patterns

**Files:**
- `MedicalBenchmarkTest.java`
- `MedicalBenchmarkTest2.java`
- `SapBenchmarkTest.java`

Update `buildGraphQuery()` to create GraphPattern objects:

```java
private GraphQuery buildGraphQuery(String scenario, List<String> hints) {
    // Build patterns from hints instead of just TraversalHint
    List<GraphPattern> patterns = buildPatterns(scenario, hints);
    
    return new GraphQuery(
        scenario,
        List.of(), // No targets - use patterns
        null, // No traversal hint
        patterns, // NEW: structured patterns
        null, // No combinator for single pattern
        RankingStrategy.HYBRID,
        3, 10, true, 4000, 100, 100
    );
}

private List<GraphPattern> buildPatterns(String scenario, List<String> hints) {
    return switch (scenario) {
        case "Multi-Hop Contraindication Discovery" -> List.of(
            new GraphPattern(
                "multi_hop_contra",
                List.of(
                    new TraversalStep("Patient", "HAS_CONDITION", "Condition", 0),
                    new TraversalStep("Condition", "DIAGNOSED_IN", "Patient", 1),
                    new TraversalStep("Patient", "TAKES_MEDICATION", "Medication", 2)
                ),
                List.of(
                    Constraint.propertyIn("Medication", "name", List.of("Methotrexate", "Prednisone"), 2)
                ),
                "Multi-hop contraindication"
            )
        );
        // ... other scenarios
    };
}
```

**Deliverables:**
- [ ] All 12 benchmark scenarios converted to patterns
- [ ] Tests pass
- [ ] Run evaluate_benchmarks.py
- [ ] Validate 5-15x improvement over Vector RAG

---

### Phase 8: Documentation & Examples (Week 6)

#### 8.1 Update Documentation

**Files:**
- `README.md` - Add pattern examples
- `QUICKSTART.md` - Update with pattern usage
- `docs/EXAMPLES.md` - Create examples document

#### 8.2 Create Example Patterns

Create examples for common use cases:
- Single-hop relationship
- Multi-hop traversal (3-5 hops)
- Constraint filtering
- Pattern intersection (AND)
- Pattern union (OR)
- Sequential patterns

**Deliverables:**
- [ ] Documentation updated
- [ ] Examples created
- [ ] Migration guide written
- [ ] API reference updated

---

## Testing Strategy

### Unit Tests
- DTO validation
- Constraint evaluation
- Pattern execution logic
- Ranking strategies

### Integration Tests
- End-to-end pattern retrieval
- Combinator execution
- Backward compatibility
- MCP tool integration

### Performance Tests
- Pattern execution on large graphs (100K nodes)
- Multi-pattern intersection performance
- Memory usage with deep paths (8 hops)

### Benchmark Validation
- Run all 12 enhanced scenarios
- Validate F1 improvements (target: 5-15x)
- Compare with Vector RAG baseline

---

## Risk Mitigation

### Backward Compatibility
- Keep existing target-based queries working
- Add feature flag (`cef.search.patterns.enabled`)
- Gradual migration path

### Performance
- Limit max paths to prevent explosion
- Add timeout for pattern execution
- Monitor memory usage on deep traversals

### Complexity
- Start with simple patterns in benchmarks
- Add complexity gradually
- Comprehensive logging for debugging

---

## Success Criteria

1. ✅ All 12 benchmark scenarios use patterns
2. ✅ F1 scores improve 5-15x over Vector RAG
3. ✅ Backward compatibility maintained
4. ✅ Performance acceptable (<2s for 5-hop patterns)
5. ✅ Documentation complete with examples
6. ✅ LLM can construct patterns via MCP tool

---

## Timeline

| Phase | Duration | Dependencies |
|-------|----------|-------------|
| Phase 1: DTOs | Week 1 | None |
| Phase 2: Update DTOs | Week 1-2 | Phase 1 |
| Phase 3: Pattern Execution | Week 2-3 | Phase 1, 2 |
| Phase 4: Enhance Retriever | Week 3-4 | Phase 3 |
| Phase 5: MCP Tool | Week 4 | Phase 4 |
| Phase 6: Configuration | Week 4 | Phase 4 |
| Phase 7: Benchmarks | Week 5 | Phase 4, 5, 6 |
| Phase 8: Documentation | Week 6 | All |

**Total: 6 weeks**

---

## Conclusion

This implementation enhances the existing hybrid retrieval system with structured pattern support, enabling multi-hop reasoning that fundamentally outperforms Vector RAG. The approach maintains backward compatibility while adding powerful new capabilities for complex graph queries.
