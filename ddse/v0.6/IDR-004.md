# IDR-004: Enterprise Production Readiness for CEF v0.6

**Status:** ‚úÖ PHASE 4 COMPLETE  
**Date:** 2025-12-07  
**Author:** Mahmudur R Manna (mrmanna)  
**Deciders:** DDSE Foundation Core Team  
**Related:** IDR-001 (Unified Storage Adapter Support), ADR-002 (Knowledge Model Design)

---

## Implementation Progress (Updated: 2025-12-07)

| Batch | Feature | Status | Tests |
|-------|---------|--------|-------|
| 1 | **Resilience Infrastructure** | ‚úÖ COMPLETE | 7 tests |
| 2 | **Thread Safety** | ‚úÖ COMPLETE | 21 tests |
| 3 | **Observability** | ‚úÖ COMPLETE | Compiles |
| 4 | **Neo4j Graph Adapter** | ‚úÖ COMPLETE | 18 tests |
| 5 | **Input Validation** | ‚úÖ COMPLETE | 29 tests |
| 6 | **PostgreSQL Graph Adapters** | ‚úÖ COMPLETE | 36 tests |
| 7 | **Docker Compose** | ‚úÖ COMPLETE | - |
| 8 | **Security** | ‚úÖ COMPLETE | 49 tests |
| 9 | **Configuration Hardening** | ‚úÖ COMPLETE | 18 tests |

**Total New Tests:** 178+ tests passing  
**All tests use real infrastructure (Ollama, Neo4j, PostgreSQL via Testcontainers) - NO MOCKS**

### Batch 8: Security Implementation
- `CefSecurityProperties.java` - Security configuration (JWT, API-Key, OAuth2)
- `InputSanitizer.java` - SQL/Cypher injection, XSS, prompt injection prevention
- `SecurityAuditLogger.java` - Audit logging for security events
- `CefExceptionHandler.java` - Sanitized error responses
- `CefSecurityAutoConfiguration.java` - Auto-configuration for security beans
- `InputSanitizerTest.java` - 33 tests for input sanitization
- `SecurityAuditLoggerTest.java` - 16 tests for audit logging

### Batch 9: Configuration Hardening
- Enhanced `CefProperties.java` with JSR-380 validation constraints
- Added validation for: dimension (128-4096), token budget (100-128K), batch size, cache TTL
- `CefPropertiesValidationTest.java` - 18 validation tests

---

## Graph Store Architecture Decision

### User-Configurable Graph Store Selection

CEF v0.6 provides **four production-ready graph store implementations** selectable via configuration:

```yaml
cef:
  graph:
    store: neo4j | pg-age | pg-sql | in-memory
```

### Implementation Matrix

| Store | Backend | Best For | Traversal Performance |
|-------|---------|----------|----------------------|
| `Neo4jGraphStore` | Neo4j Community | Large graphs, complex traversals | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Native graph |
| `PgAgeGraphStore` | PostgreSQL + Apache AGE | Single-DB deployments, Cypher queries | ‚≠ê‚≠ê‚≠ê‚≠ê Cypher on PG |
| `PgSqlGraphStore` | Pure PostgreSQL SQL | Maximum compatibility, simple graphs | ‚≠ê‚≠ê‚≠ê SQL joins |
| `InMemoryGraphStore` | JGraphT | Development, testing, <100K nodes | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê RAM speed |

### Trade-off Analysis

#### Neo4jGraphStore
- **Pros:** Native graph, fastest traversals at any depth, Cypher query language, ACID
- **Cons:** Additional service to manage, separate from vector store
- **Use When:** High-performance requirements, complex graph patterns, >1M nodes

#### PgAgeGraphStore (PostgreSQL + Apache AGE)
- **Pros:** Single database for graph+vectors, Cypher support, good performance
- **Cons:** Requires AGE extension, less mature than Neo4j
- **Use When:** Want unified PostgreSQL deployment with Cypher queries

#### PgSqlGraphStore (Pure PostgreSQL)
- **Pros:** Zero extensions, maximum compatibility, simple adjacency tables
- **Cons:** Slower for deep traversals (recursive CTEs), SQL complexity
- **Use When:** Existing PostgreSQL infrastructure, 1-2 hop traversals only

#### InMemoryGraphStore (JGraphT)
- **Pros:** Zero setup, fastest for small graphs, great for development
- **Cons:** Not persistent, memory-bound, single-process only
- **Use When:** Development, testing, prototyping, <100K nodes

### Deployment Configurations

```yaml
# Production: High-performance dual-store
cef:
  graph:
    store: neo4j
  vector:
    store: postgresql

# Production: Unified PostgreSQL (with AGE)
cef:
  graph:
    store: pg-age
  vector:
    store: postgresql

# Production: Unified PostgreSQL (pure SQL)
cef:
  graph:
    store: pg-sql
  vector:
    store: postgresql

# Development: Zero infrastructure
cef:
  graph:
    store: in-memory
  vector:
    store: in-memory
```

---

### Completed Components

#### Batch 1: Resilience Infrastructure
- `CefResilienceProperties.java` - Externalized configuration for retry, circuit breaker, timeout
- `CefResilienceAutoConfiguration.java` - Auto-configuration for Resilience4j beans
- `ResilientEmbeddingService.java` - Wrapper with retry, circuit breaker, timeout
- `ResilientEmbeddingServiceTest.java` - 7 tests with real Ollama (nomic-embed-text)

#### Batch 2: Thread Safety
- `ThreadSafeKnowledgeGraph.java` - ReadWriteLock wrapper for InMemoryKnowledgeGraph
- `ThreadSafeKnowledgeGraphTest.java` - 21 concurrent tests including stress tests

#### Batch 3: Observability
- `CefHealthIndicator.java` - Combined health indicator for CEF components
- `KnowledgeGraphHealthIndicator.java` - Graph-specific health checks
- `CefMetrics.java` - Micrometer metrics binder for graph statistics
- Updated `application.yml` with actuator endpoints

#### Batch 4: Neo4j Graph Adapter
- `Neo4jGraphStore.java` - Full GraphStore implementation using Neo4j Cypher
- `Neo4jGraphStoreIntegrationTest.java` - 18 tests using Testcontainers
- Added Neo4j driver and Spring Data Neo4j dependencies
- Updated docker-compose.yml with Neo4j Community service

#### Batch 5: Input Validation
- `CefValidationConfig.java` - Bean validation configuration
- `ValidatedRetrievalRequest.java` - JSR-380 validated retrieval DTO
- `ValidatedNodeInput.java` - JSR-380 validated node input DTO
- `ValidatedEdgeInput.java` - JSR-380 validated edge input DTO
- `InputValidationTest.java` - 29 validation tests

#### Batch 6: PostgreSQL Graph Adapters
- `PgSqlGraphStore.java` - Pure SQL adjacency list implementation
- `PgAgeGraphStore.java` - Apache AGE Cypher implementation
- `CefGraphStoreProperties.java` - Configuration properties for store selection
- `GraphStoreAutoConfiguration.java` - Auto-configuration for store beans
- `PgSqlGraphStoreIntegrationTest.java` - 18 tests using Testcontainers
- `PgAgeGraphStoreIntegrationTest.java` - 18 tests using Testcontainers

---

## Executive Summary

This Implementation Decision Record addresses the **critical production readiness gaps** identified in CEF beta-0.5 and defines the implementation roadmap for v0.6. The current release, while excellent for research and prototyping, has **56+ production blockers** spanning resilience, observability, security, and operational concerns.

**Goal:** Transform CEF from a "Disposable Research Pod" framework to an **enterprise-grade production system** while **maintaining developer ergonomics** for local development with in-memory components.

---

## Context and Problem Statement

### Current State (beta-0.5)

CEF beta-0.5 was explicitly designed as a **Community/Research Release**:

> *"It is optimized for ease of use and experimentation, not for high-concurrency enterprise production environments."*

This was appropriate for initial validation, but user feedback and enterprise adoption interest requires addressing fundamental gaps.

### Brutal Honesty: What's Broken

Based on comprehensive code audit, the following **critical issues** block production deployment:

| Category | Critical | High | Medium | Total |
|----------|----------|------|--------|-------|
| Resilience & Error Handling | 3 | 2 | 2 | 7 |
| Thread Safety & Concurrency | 2 | 2 | 1 | 5 |
| Resource Management | 1 | 1 | 3 | 5 |
| Configuration & Validation | 1 | 2 | 4 | 7 |
| Observability | 2 | 3 | 1 | 6 |
| Security | 2 | 2 | 4 | 8 |
| Data Integrity | 1 | 2 | 2 | 5 |
| **Test Coverage Gaps** | **3** | **4** | **2** | **9** |
| **TOTAL** | **15** | **18** | **19** | **52** |

---

## Decision Drivers

1. **Enterprise Adoption** - Organizations want to use CEF in production but cannot justify the operational risk
2. **Competitive Pressure** - Other context engineering solutions are emerging; CEF must differentiate on production-readiness
3. **Framework Credibility** - Being "research-only" limits adoption and contribution
4. **Backward Compatibility** - Existing users must not be broken; local development must remain simple
5. **Developer Experience** - Production features should be opt-in, not mandatory complexity

---

## Critical Issues Analysis

### 1. RESILIENCE & ERROR HANDLING üî¥ CRITICAL

#### 1.1 No Retry Mechanisms for External Services

**Files Affected:**
- `DefaultEmbeddingService.java` (lines 26-39)
- `DefaultKnowledgeIndexer.java` (lines 179-199)
- `DefaultContextRetriever.java` (lines 175-190)

**Current Code:**
```java
// DefaultEmbeddingService.java - No retry, no timeout
public Mono<float[]> embed(String text) {
    return Mono.fromCallable(() -> {
        EmbeddingResponse response = embeddingModel.embedForResponse(List.of(text));
        return response.getResults().get(0).getOutput();
    });
}
```

**Problem:** When Ollama/OpenAI has transient failures (rate limits, network blips, cold starts), the entire indexing operation fails. No retry, no backoff, no circuit breaker.

**Impact:** 
- Index jobs fail intermittently in production
- Users see cryptic errors
- No graceful degradation

---

#### 1.2 No Circuit Breakers

**Problem:** If embedding service goes down, CEF hammers it with requests causing:
- Cascading failures across all indexing operations
- Resource exhaustion (blocked threads)
- Extended recovery time

**Evidence:** Grep for `CircuitBreaker`, `Resilience4j` found **zero matches** in production code.

---

#### 1.3 Silent Error Swallowing

**File:** `DefaultKnowledgeIndexer.java` (lines 193-199)

```java
.onErrorResume(e -> {
    log.error("Failed to generate embedding for node: {}", node.getId(), e);
    return Mono.just(node); // Continues WITHOUT embedding - silent data corruption
});
```

**Problem:** Nodes are saved without embeddings. Later, vector searches silently exclude these nodes. Users don't know they have incomplete data.

---

#### 1.4 No Timeout Configuration

**Evidence:** No `timeout()` operators found in any reactive chain calling external services.

**Problem:** A hanging LLM call blocks indefinitely, consuming threads from `boundedElastic` scheduler until exhaustion.

---

### 2. THREAD SAFETY & CONCURRENCY üî¥ CRITICAL

#### 2.1 JGraphT Not Thread-Safe

**File:** `InMemoryKnowledgeGraph.java`

```java
// Write operations ARE synchronized
public synchronized void addNode(Node node) { ... }
public synchronized void addEdge(Edge edge) { ... }

// Read operations are NOT synchronized - RACE CONDITION
public Optional<Node> findNode(UUID nodeId) {
    return Optional.ofNullable(nodeIndex.get(nodeId));  // ConcurrentHashMap OK
}

public Set<Edge> getEdges(UUID nodeId) {
    Set<EdgeWrapper> wrappers = graph.edgesOf(nodeId);  // JGraphT NOT thread-safe
    return wrappers.stream().map(EdgeWrapper::getEdge).collect(Collectors.toSet());
}
```

**Problem:** JGraphT's `DirectedWeightedPseudograph` is **not thread-safe**. Concurrent reads during writes can cause:
- `ConcurrentModificationException`
- Inconsistent reads (partial edge sets)
- Silent data corruption

**Evidence from KNOWN_ISSUES.md:**
> *"JGraphT in-memory store is not thread-safe by default. Edge additions during concurrent node updates may be inconsistent."*

This is documented but **not fixed**.

#### 2.2 Existing Concurrency Test is Inadequate

**File:** `InMemoryKnowledgeGraphTest.java` (lines 413-438)

```java
@Test
void shouldHandleConcurrentAccess() throws InterruptedException {
    // ONLY tests concurrent WRITES - this PASSES
    for (int i = 0; i < threadCount; i++) {
        executor.submit(() -> {
            for (int j = 0; j < operationsPerThread; j++) {
                graph.addNode(node);  // Synchronized - works fine
            }
        });
    }
    // NEVER tests concurrent READS during WRITES - the actual bug!
}
```

**Problem:** The test gives false confidence. It tests concurrent writes (which are synchronized) but **never tests the actual failure mode**: concurrent reads during writes via `graph.edgesOf()` which is NOT synchronized.

---

#### 2.3 Dual Persistence Race Condition

**File:** `InMemoryGraphStore.java` (via InMemoryKnowledgeGraph)

When using DuckDB + JGraphT together:
1. Node saved to DuckDB ‚úÖ
2. Node added to in-memory graph ‚ùå (fails)
3. **State inconsistent** - DB has node, memory doesn't

No compensating transaction, no reconciliation, no detection.

---

### 3. RESOURCE MANAGEMENT üü° HIGH

#### 3.1 Connection Leak in DuckDB Initialization

**File:** `DuckDbChunkStore.java` (lines 43-48)

```java
try {
    String url = jdbcTemplate.getDataSource().getConnection().getMetaData().getURL();
    log.info("DuckDbChunkStore initialized with database URL: {}", url);
} catch (Exception e) {
    log.warn("Could not retrieve database URL: {}", e.getMessage());
}
```

**Problem:** Connection obtained but never closed. Minor, but indicates resource handling discipline issues.

---

#### 3.2 No Connection Pooling for DuckDB

**Problem:** Each DuckDB operation potentially creates new connection. No HikariCP configuration for embedded DuckDB.

---

#### 3.3 Memory Leak Risk in Graph Loading

**File:** `InMemoryKnowledgeGraph.java` (lines 481-493)

```java
long nodeCount = nodes.doOnNext(this::addNode).count().block();  // BLOCKS
long edgeCount = edges.doOnNext(this::addEdge).count().block();  // BLOCKS
```

**Problem:** Blocks on reactive streams without backpressure. Large graphs cause OOM.

---

### 4. OBSERVABILITY üî¥ CRITICAL

#### 4.1 Zero Metrics Integration

**Evidence:** Grep for `@Timed`, `@Counted`, `MeterRegistry`, `micrometer` found **zero matches** in production code.

**Missing Metrics:**
- Embedding generation latency/success/failure rates
- LLM call latency/tokens used
- Graph traversal performance
- Vector search latency
- Request throughput/error rates
- Memory usage for in-memory graph

**Impact:** In production, you're flying blind. No alerting, no dashboards, no capacity planning.

---

#### 4.2 No Distributed Tracing

**Problem:** Reactive chains lose trace context. Cannot trace a request through:
```
MCP Tool ‚Üí Retriever ‚Üí GraphStore ‚Üí VectorStore ‚Üí EmbeddingService
```

---

#### 4.3 Fake Health Checks

**File:** `McpRestController.java` (lines 71-76)

```java
@GetMapping("/health")
public Mono<Map<String, String>> health() {
    return Mono.just(Map.of(
        "status", "UP",
        "service", "CEF MCP Tool"));  // ALWAYS returns UP!
}
```

**Problem:** Health check doesn't verify:
- Database connectivity
- Embedding service availability
- LLM service availability
- In-memory graph state

Kubernetes will think pod is healthy when it's actually broken.

---

#### 4.4 No Actuator Endpoints

**Evidence:** `spring-boot-starter-actuator` not in `pom.xml`. No `/actuator/*` endpoints.

---

### 5. SECURITY üî¥ CRITICAL

#### 5.1 No Authentication/Authorization

**Evidence:** Grep for `@PreAuthorize`, `@Secured`, `SecurityContext`, `Authentication` found **zero matches**.

**Problem:** MCP REST API is completely open. Anyone can:
- Query your knowledge graph
- Extract all your indexed content
- Potentially inject malicious queries

---

#### 5.2 Error Message Information Leakage

**File:** `McpContextTool.java` (line 111)

```java
return "Error executing tool: " + e.getMessage();
```

**Problem:** Internal exceptions (including stack traces, database errors, file paths) are returned to LLM/caller.

---

#### 5.3 Secrets in Default Configuration

**File:** `application.yml`

```yaml
postgresql:
  username: cef_user
  password: cef_password  # Default password committed!
```

---

#### 5.4 No Input Validation

**Evidence:** Grep for `@Valid`, `@Validated`, `@NotNull`, `@Size` found **zero matches** in production code.

**Problem:** Malformed requests can cause:
- Negative `topK` values
- Extremely long queries (DoS via embedding)
- Graph traversal depth attacks

---

### 6. CONFIGURATION & VALIDATION üü° HIGH

#### 6.1 Hardcoded Magic Numbers

```java
// DefaultKnowledgeIndexer.java
.flatMap(this::generateEmbeddingForNode, 10);  // Hardcoded concurrency
.flatMap(this::generateEmbeddingForChunk, 20); // Hardcoded concurrency

// ContextAssembler.java
private static final double CHARS_PER_TOKEN = 4.0;  // Hardcoded

// DefaultContextRetriever.java
.limit(10);  // Hardcoded keyword limit
```

**Problem:** Cannot tune performance without code changes.

---

#### 6.2 No Bounds Checking on Traversal Depth

**Problem:** Request with `depth=100` causes stack overflow or OOM. Config has `max-traversal-depth: 5` but it's **not enforced**.

---

#### 6.3 Schema Initialization Failures Silently Ignored

**File:** `DuckDbChunkStore.java`

```java
} catch (Exception e) {
    log.warn("Failed to initialize DuckDB schema: {}", e.getMessage());
    // Continues anyway - subsequent operations will fail with cryptic errors
}
```

---

### 7. DATA INTEGRITY üü° HIGH

#### 7.1 No Transaction Management

**Evidence:** Grep for `@Transactional` found **zero matches** in production code.

**Problem:** Batch operations claim transactional behavior but aren't:
```java
/**
 * Transactional: all succeed or all fail.  // Documentation LIES
 */
Mono<BatchIndexResult> indexBatch(BatchInput batch);  // No @Transactional
```

---

#### 7.2 Incomplete Implementations Return Null/Empty

**File:** `InMemoryGraphStore.java`

```java
@Override
public Mono<Edge> getEdge(UUID edgeId) {
    return Mono.<Edge>fromCallable(() -> {
        return null;  // Not implemented, returns null
    }).subscribeOn(Schedulers.boundedElastic());
}

@Override
public Flux<Edge> findEdgesByRelationType(String relationType) {
    return Flux.empty();  // Not implemented, returns empty
}
```

**Problem:** Callers don't know if edge doesn't exist or method isn't implemented.

---

## Proposed Solution: Production Hardening for v0.6

### Design Principles

1. **Opt-In Complexity** - Production features are enabled via configuration, not mandatory
2. **Local Development First** - Default configuration works with `docker-compose up` and in-memory stores
3. **Fail Fast** - Production mode validates configuration at startup
4. **Observable by Default** - Metrics and health checks are automatic
5. **Secure by Default** - Production mode requires explicit security bypass

### Architecture: Production Profile

```yaml
# application.yml - Development (default)
cef:
  profile: development  # Relaxed validation, in-memory OK

# application-production.yml - Production
cef:
  profile: production
  resilience:
    retry:
      enabled: true
      max-attempts: 3
      backoff: exponential
    circuit-breaker:
      enabled: true
      failure-threshold: 5
      wait-duration: 30s
    timeout:
      embedding: 30s
      llm: 60s
      database: 10s
  observability:
    metrics:
      enabled: true
      export: prometheus
    tracing:
      enabled: true
      sampling-rate: 0.1
    health:
      detailed: true
  security:
    enabled: true
    authentication: jwt  # or api-key, oauth2
```

---

## Implementation Plan

### Phase 1: Resilience Foundation (Week 1-2)

#### 1.1 Add Resilience4j Dependency

```xml
<!-- pom.xml -->
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot3</artifactId>
</dependency>
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-reactor</artifactId>
</dependency>
```

#### 1.2 Implement Retry with Circuit Breaker

```java
@Service
public class ResilientEmbeddingService implements EmbeddingService {
    
    private final EmbeddingModel embeddingModel;
    private final CircuitBreaker circuitBreaker;
    private final Retry retry;
    private final TimeLimiter timeLimiter;
    
    @Override
    public Mono<float[]> embed(String text) {
        return Mono.fromCallable(() -> embeddingModel.embed(text))
            .transformDeferred(CircuitBreakerOperator.of(circuitBreaker))
            .transformDeferred(RetryOperator.of(retry))
            .timeout(Duration.ofSeconds(30))
            .subscribeOn(Schedulers.boundedElastic())
            .doOnError(e -> log.error("Embedding failed after retries", e));
    }
}
```

#### 1.3 Configuration-Driven Resilience

```yaml
cef:
  resilience:
    embedding:
      retry:
        max-attempts: 3
        wait-duration: 1s
        exponential-backoff-multiplier: 2
      circuit-breaker:
        failure-rate-threshold: 50
        wait-duration-in-open-state: 30s
        sliding-window-size: 10
      timeout: 30s
    llm:
      retry:
        max-attempts: 2
        wait-duration: 2s
      circuit-breaker:
        failure-rate-threshold: 50
        wait-duration-in-open-state: 60s
      timeout: 120s
```

#### 1.4 Proper Error Handling

```java
// Replace silent error swallowing with explicit handling
private Mono<Node> generateEmbeddingForNode(Node node) {
    return embeddingService.embed(node.getVectorizableContent())
        .map(embedding -> {
            Chunk chunk = new Chunk();
            chunk.setContent(node.getVectorizableContent());
            chunk.setEmbedding(embedding);
            chunk.setLinkedNodeId(node.getId());
            return chunk;
        })
        .flatMap(chunkStore::save)
        .thenReturn(node)
        .onErrorResume(e -> {
            if (properties.getIndexing().isFailOnEmbeddingError()) {
                return Mono.error(new EmbeddingGenerationException(node.getId(), e));
            }
            // Track metrics for partial failures
            meterRegistry.counter("cef.embedding.failures").increment();
            log.warn("Embedding failed for node {}, continuing without embedding", node.getId());
            return Mono.just(node.withEmbeddingStatus(EmbeddingStatus.FAILED));
        });
}
```

---

### Phase 2: Thread Safety (Week 2-3)

#### 2.1 Thread-Safe Graph Wrapper

```java
@Component
public class ThreadSafeKnowledgeGraph {
    
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Graph<UUID, EdgeWrapper> graph;
    private final Map<UUID, Node> nodeIndex;
    
    public void addNode(Node node) {
        lock.writeLock().lock();
        try {
            graph.addVertex(node.getId());
            nodeIndex.put(node.getId(), node);
        } finally {
            lock.writeLock().unlock();
        }
    }
    
    public Set<Edge> getEdges(UUID nodeId) {
        lock.readLock().lock();
        try {
            if (!graph.containsVertex(nodeId)) {
                return Set.of();
            }
            // Return defensive copy
            return graph.edgesOf(nodeId).stream()
                .map(EdgeWrapper::getEdge)
                .collect(Collectors.toUnmodifiableSet());
        } finally {
            lock.readLock().unlock();
        }
    }
}
```

#### 2.2 Copy-On-Write Option for Read-Heavy Workloads

```yaml
cef:
  graph:
    concurrency-strategy: read-write-lock  # or copy-on-write
```

---

### Phase 3: Observability (Week 3-4)

#### 3.1 Add Actuator and Micrometer

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>
```

#### 3.2 Instrument Key Operations

```java
@Service
public class InstrumentedEmbeddingService implements EmbeddingService {
    
    private final MeterRegistry meterRegistry;
    private final Timer embeddingTimer;
    private final Counter embeddingCounter;
    
    public InstrumentedEmbeddingService(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.embeddingTimer = Timer.builder("cef.embedding.duration")
            .description("Time to generate embeddings")
            .register(meterRegistry);
        this.embeddingCounter = Counter.builder("cef.embedding.total")
            .description("Total embedding requests")
            .register(meterRegistry);
    }
    
    @Override
    public Mono<float[]> embed(String text) {
        return Mono.deferContextual(ctx -> {
            long start = System.nanoTime();
            return delegate.embed(text)
                .doOnSuccess(v -> {
                    embeddingTimer.record(System.nanoTime() - start, TimeUnit.NANOSECONDS);
                    embeddingCounter.increment();
                })
                .doOnError(e -> meterRegistry.counter("cef.embedding.errors").increment());
        });
    }
}
```

#### 3.3 Real Health Checks

```java
@Component
public class CefHealthIndicator implements ReactiveHealthIndicator {
    
    private final GraphStore graphStore;
    private final ChunkStore chunkStore;
    private final EmbeddingModel embeddingModel;
    
    @Override
    public Mono<Health> health() {
        return Mono.zip(
            checkGraphStore(),
            checkChunkStore(),
            checkEmbeddingService()
        ).map(tuple -> {
            Health.Builder builder = Health.up();
            if (tuple.getT1().getStatus() != Status.UP) builder.down();
            if (tuple.getT2().getStatus() != Status.UP) builder.down();
            if (tuple.getT3().getStatus() != Status.UP) builder.down();
            return builder
                .withDetail("graphStore", tuple.getT1())
                .withDetail("chunkStore", tuple.getT2())
                .withDetail("embeddingService", tuple.getT3())
                .build();
        });
    }
    
    private Mono<Health> checkEmbeddingService() {
        return Mono.fromCallable(() -> {
            // Lightweight health check - embed single token
            embeddingModel.embed("health");
            return Health.up().build();
        })
        .timeout(Duration.ofSeconds(5))
        .onErrorResume(e -> Mono.just(Health.down(e).build()));
    }
}
```

#### 3.4 Key Metrics to Export

| Metric | Type | Description |
|--------|------|-------------|
| `cef.embedding.duration` | Timer | Embedding generation latency |
| `cef.embedding.errors` | Counter | Failed embedding requests |
| `cef.retrieval.duration` | Timer | Context retrieval latency |
| `cef.retrieval.strategy` | Counter | Strategy usage (graph/hybrid/vector) |
| `cef.graph.nodes` | Gauge | Current node count |
| `cef.graph.edges` | Gauge | Current edge count |
| `cef.graph.memory` | Gauge | In-memory graph size (bytes) |
| `cef.circuitbreaker.state` | Gauge | Circuit breaker state |

---

### Phase 4: Security (Week 4-5)

#### 4.1 Add Spring Security

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
    <optional>true</optional>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
    <optional>true</optional>
</dependency>
```

#### 4.2 Configuration-Driven Security

```yaml
cef:
  security:
    enabled: false  # Default: disabled for development
    
# Production override
---
spring:
  config:
    activate:
      on-profile: production
cef:
  security:
    enabled: true
    type: jwt  # jwt, api-key, or oauth2
    jwt:
      issuer-uri: https://auth.example.com
      audience: cef-api
    api-key:
      header: X-API-Key
      keys:
        - ${CEF_API_KEY_1}
        - ${CEF_API_KEY_2}
```

#### 4.3 Security Auto-Configuration

```java
@Configuration
@ConditionalOnProperty(name = "cef.security.enabled", havingValue = "true")
public class CefSecurityAutoConfiguration {
    
    @Bean
    public SecurityWebFilterChain securityFilterChain(ServerHttpSecurity http) {
        return http
            .authorizeExchange(exchanges -> exchanges
                .pathMatchers("/actuator/health", "/actuator/info").permitAll()
                .pathMatchers("/api/mcp/**").authenticated()
                .anyExchange().authenticated()
            )
            .oauth2ResourceServer(oauth2 -> oauth2.jwt(Customizer.withDefaults()))
            .build();
    }
}
```

#### 4.4 Input Validation

```java
public record RetrievalRequest(
    @Valid GraphQuery graphQuery,
    @NotBlank @Size(max = 10000) String query,
    @Min(100) @Max(32000) int maxTokenBudget,
    @Min(1) @Max(100) int topK,
    @Min(1) @Max(1000) int maxGraphNodes,
    @Size(max = 50) List<@Size(max = 100) String> semanticKeywords
) {
    public RetrievalRequest {
        if (maxTokenBudget == 0) maxTokenBudget = 4000;
        if (topK == 0) topK = 10;
        if (maxGraphNodes == 0) maxGraphNodes = 100;
    }
}
```

#### 4.5 Sanitized Error Responses

```java
@ControllerAdvice
public class CefExceptionHandler {
    
    @ExceptionHandler(Exception.class)
    public Mono<ResponseEntity<ErrorResponse>> handleException(Exception e) {
        String errorId = UUID.randomUUID().toString();
        log.error("Request failed [errorId={}]", errorId, e);
        
        // Never expose internal details
        return Mono.just(ResponseEntity
            .status(HttpStatus.INTERNAL_SERVER_ERROR)
            .body(new ErrorResponse(
                errorId,
                "An internal error occurred. Reference: " + errorId,
                Instant.now()
            )));
    }
}
```

---

### Phase 5: Configuration & Validation (Week 5-6)

#### 5.1 Externalize All Magic Numbers

```java
@ConfigurationProperties(prefix = "cef")
@Validated
public class CefProperties {
    
    @Valid
    private IndexingConfig indexing = new IndexingConfig();
    
    @Valid
    private RetrievalConfig retrieval = new RetrievalConfig();
    
    public static class IndexingConfig {
        @Min(1) @Max(100)
        private int embeddingConcurrency = 10;
        
        @Min(1) @Max(100)
        private int chunkEmbeddingConcurrency = 20;
        
        private boolean failOnEmbeddingError = false;  // true in production
    }
    
    public static class RetrievalConfig {
        @Min(1) @Max(10)
        private int maxTraversalDepth = 5;
        
        @Min(1) @Max(1000)
        private int defaultTopK = 10;
        
        @Min(1) @Max(10000)
        private int maxTopK = 100;
        
        private double charsPerToken = 4.0;
    }
}
```

#### 5.2 Startup Validation

```java
@Component
@ConditionalOnProperty(name = "cef.profile", havingValue = "production")
public class ProductionStartupValidator implements ApplicationRunner {
    
    @Override
    public void run(ApplicationArguments args) {
        List<String> errors = new ArrayList<>();
        
        // Validate required external services
        if (!isEmbeddingServiceReachable()) {
            errors.add("Embedding service not reachable");
        }
        
        // Validate security is enabled
        if (!securityEnabled) {
            errors.add("Security must be enabled in production (cef.security.enabled=true)");
        }
        
        // Validate not using in-memory stores in production
        if ("jgrapht".equals(graphStore) && !allowInMemoryGraph) {
            errors.add("In-memory graph store not recommended for production");
        }
        
        if (!errors.isEmpty()) {
            throw new ProductionValidationException(errors);
        }
    }
}
```

---

### Phase 6: Unified Storage Adapters for Scale (Week 6-7)

**Reference:** IDR-001 (Unified Storage Adapter Support)

#### 6.1 The Scale Problem

Current architecture limits production scale:
- **JGraphT**: ~100K nodes max (in-memory)
- **DuckDB**: ~50K chunks before vector search degrades (brute-force, no HNSW)
- **Dual persistence**: 2 databases = operational complexity + no transactional consistency

**Solution:** Support unified databases that handle **both graph AND vectors** natively:

| Database | Graph | Vector | Scale | Status |
|----------|-------|--------|-------|--------|
| Neo4j 5.11+ | Native | Native (vector index) | Millions | v0.6 |
| PostgreSQL + pgvector + Apache AGE | Recursive CTE | HNSW | Millions | v0.6 |
| ArangoDB 3.12+ | Native | Native | Millions | v0.7 |
| DuckDB + JGraphT | Separate | Brute-force | ~100K | Current |

#### 6.2 Neo4j Unified Adapter (Priority)

```java
// Single database for both graph AND vector operations
@Component
@ConditionalOnProperty(name = "cef.storage.provider", havingValue = "neo4j")
public class Neo4jUnifiedAdapter implements GraphStore, VectorStore {
    
    private final Driver neo4jDriver;
    
    // Graph operations - native Cypher
    @Override
    public Mono<Node> addNode(Node node) {
        String cypher = """
            CREATE (n:Node {id: $id, label: $label, properties: $props})
            RETURN n
            """;
        return executeQuery(cypher, nodeToParams(node));
    }
    
    // Vector operations - native vector index
    @Override
    public Flux<Chunk> similaritySearch(float[] embedding, int topK, Double threshold) {
        String cypher = """
            CALL db.index.vector.queryNodes('chunk_embeddings', $topK, $embedding)
            YIELD node, score
            WHERE score >= $threshold
            RETURN node, score
            """;
        return executeQuery(cypher, Map.of("embedding", embedding, "topK", topK));
    }
    
    // UNIFIED: Single-transaction hybrid query (the killer feature)
    public Flux<SearchResult> hybridSearch(float[] embedding, int depth, String[] relationTypes) {
        String cypher = """
            CALL db.index.vector.queryNodes('chunk_embeddings', 10, $embedding) YIELD node AS chunk, score
            MATCH (chunk)-[:LINKED_TO]->(startNode:Node)
            MATCH path = (startNode)-[r*1..$depth]-(connected:Node)
            WHERE type(r) IN $types
            RETURN DISTINCT connected, chunk, score
            ORDER BY score DESC
            """;
        return executeQuery(cypher, params);  // ONE query, ONE transaction
    }
}
```

#### 6.3 PostgreSQL Unified Adapter

```java
// PostgreSQL with pgvector (vectors) + recursive CTE (graph traversal)
@Component
@ConditionalOnProperty(name = "cef.storage.provider", havingValue = "postgresql")
public class PostgresUnifiedAdapter implements GraphStore, VectorStore {
    
    // Graph traversal via recursive CTE
    @Override
    public Flux<Node> findKHopNeighbors(UUID nodeId, int depth) {
        String sql = """
            WITH RECURSIVE neighbors AS (
                SELECT target_node_id AS id, 1 AS depth
                FROM edges WHERE source_node_id = $1
                UNION
                SELECT e.target_node_id, n.depth + 1
                FROM edges e JOIN neighbors n ON e.source_node_id = n.id
                WHERE n.depth < $2
            )
            SELECT * FROM nodes WHERE id IN (SELECT id FROM neighbors)
            """;
        return executeQuery(sql, nodeId, depth);
    }
    
    // Vector search via pgvector HNSW
    @Override
    public Flux<Chunk> similaritySearch(float[] embedding, int topK, Double threshold) {
        String sql = """
            SELECT *, 1 - (embedding <=> $1::vector) AS score
            FROM chunks
            WHERE 1 - (embedding <=> $1::vector) >= $2
            ORDER BY embedding <=> $1::vector
            LIMIT $3
            """;
        return executeQuery(sql, embedding, threshold, topK);
    }
}
```

#### 6.4 Configuration-Driven Selection

```yaml
# Option 1: Unified (recommended for production)
cef:
  storage:
    provider: neo4j  # or postgresql, arangodb
    neo4j:
      uri: bolt://localhost:7687
      database: cef_knowledge
      vector-index: chunk_embeddings

# Option 2: Dual (backward compatible)
cef:
  storage:
    graph:
      provider: neo4j
    vector:
      provider: qdrant  # Separate specialized vector DB

# Option 3: Development (default)
cef:
  storage:
    graph:
      provider: jgrapht  # In-memory
    vector:
      provider: duckdb   # Embedded
```

#### 6.5 Scale Targets

| Configuration | Nodes | Edges | Chunks | Use Case |
|---------------|-------|-------|--------|----------|
| JGraphT + DuckDB | 100K | 500K | 50K | Development, small datasets |
| Neo4j Unified | 10M+ | 50M+ | 10M+ | Enterprise production |
| PostgreSQL Unified | 5M+ | 25M+ | 5M+ | Cost-conscious production |
| Neo4j + Qdrant | 10M+ | 50M+ | 100M+ | Maximum scale, best-of-breed |

---

### Phase 7: Data Integrity (Week 7-8)

#### 7.1 Proper Transaction Management

```java
@Service
public class TransactionalKnowledgeIndexer implements KnowledgeIndexer {
    
    @Transactional
    public Mono<BatchIndexResult> indexBatch(BatchInput batch) {
        return Flux.fromIterable(batch.nodes())
            .flatMap(this::indexNode)
            .collectList()
            .flatMap(nodes -> 
                Flux.fromIterable(batch.edges())
                    .flatMap(this::indexEdge)
                    .collectList()
                    .map(edges -> new BatchIndexResult(nodes, edges))
            );
    }
}
```

#### 6.2 Complete Incomplete Implementations

```java
@Override
public Mono<Edge> getEdge(UUID edgeId) {
    return Mono.fromCallable(() -> {
        Edge edge = edgeIndex.get(edgeId);
        if (edge == null) {
            throw new EdgeNotFoundException(edgeId);
        }
        return edge;
    }).subscribeOn(Schedulers.boundedElastic());
}

@Override
public Flux<Edge> findEdgesByRelationType(String relationType) {
    return Flux.fromIterable(edgeIndex.values())
        .filter(edge -> relationType.equals(edge.getRelationType()))
        .subscribeOn(Schedulers.boundedElastic());
}
```

---

## Maintaining Developer Experience

### Development Profile (Default)

```yaml
# application.yml (shipped with framework)
cef:
  profile: development
  
  # Relaxed settings for local development
  resilience:
    retry:
      enabled: false  # Fail fast during development
    circuit-breaker:
      enabled: false
    timeout:
      embedding: 120s  # Long timeout for slow local models
      
  observability:
    metrics:
      enabled: false  # No metrics overhead
    tracing:
      enabled: false
      
  security:
    enabled: false  # No auth for local testing
    
  graph:
    store: jgrapht  # In-memory, zero setup
    concurrency-strategy: none  # Single-threaded OK for dev
    
  database:
    type: duckdb  # Embedded, zero setup
```

### Quick Start Remains Simple

```bash
# Still works exactly as before
docker-compose up -d  # Start Ollama
mvn spring-boot:run   # Run with defaults

# For production, just add profile
mvn spring-boot:run -Dspring.profiles.active=production
```

### Configuration Profiles

| Setting | Development | Production |
|---------|-------------|------------|
| Retry | Disabled | 3 attempts, exponential backoff |
| Circuit Breaker | Disabled | 50% failure threshold |
| Timeouts | 120s (generous) | 30s embedding, 60s LLM |
| Metrics | Disabled | Prometheus export |
| Tracing | Disabled | OpenTelemetry |
| Health Checks | Basic | Full dependency checks |
| Security | Disabled | JWT/OAuth2 required |
| Graph Store | JGraphT (in-memory) | PostgreSQL or Neo4j |
| Vector Store | DuckDB (embedded) | PostgreSQL pgvector |
| Thread Safety | None | ReadWriteLock |
| Input Validation | Relaxed | Strict |

---

## Validation Criteria

### P0: Must Pass Before v0.6 Release

| Test | Description | Target |
|------|-------------|--------|
| Resilience | Embedding service restart during indexing | Zero data loss, auto-recovery |
| Concurrency | 100 concurrent reads + 10 concurrent writes | No exceptions, no corruption |
| Health | Kill embedding service, check /health | Reports DOWN within 10s |
| Security | Access /api/mcp without token (production) | 401 Unauthorized |
| Timeout | Embedding service responds after 60s | Request times out, not blocked |
| Metrics | Index 1000 nodes | Prometheus metrics available |
| Validation | Submit topK=-1 | 400 Bad Request |

### P1: Should Pass for GA

| Test | Description | Target |
|------|-------------|--------|
| Circuit Breaker | 10 consecutive embedding failures | Circuit opens, fallback triggered |
| Tracing | Query with 5-hop traversal | Full trace visible in Jaeger |
| Memory | Index 100K nodes | Memory < 2GB, no OOM |
| Batch | Index 10K nodes in batch | Atomic: all succeed or all fail |

---

## Migration Guide

### For Existing Users (beta-0.5 ‚Üí v0.6)

**No breaking changes for development usage:**

```yaml
# Your existing config continues to work
cef:
  graph:
    store: jgrapht
  database:
    type: duckdb
```

**Opting into production features:**

```yaml
# Add to your application-production.yml
cef:
  profile: production
  
  resilience:
    retry:
      enabled: true
    circuit-breaker:
      enabled: true
      
  security:
    enabled: true
    type: jwt
    jwt:
      issuer-uri: https://your-auth-server.com
```

---

## Dependencies Added

```xml
<!-- Resilience -->
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot3</artifactId>
    <version>2.2.0</version>
    <optional>true</optional>
</dependency>

<!-- Observability -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
    <optional>true</optional>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
    <optional>true</optional>
</dependency>

<!-- Security -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
    <optional>true</optional>
</dependency>

<!-- Validation -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-validation</artifactId>
</dependency>
```

---

## Timeline

| Week | Phase | Deliverables |
|------|-------|--------------|
| 1-2 | Resilience | Retry, circuit breaker, timeouts |
| 2-3 | Thread Safety | ReadWriteLock wrapper, concurrent tests |
| 3-4 | Observability | Actuator, Micrometer, health checks |
| 4-5 | Security | Auth framework, input validation |
| 5-6 | Configuration | Property validation, startup checks |
| 6-7 | **Unified Storage** | **Neo4j + PostgreSQL unified adapters (millions scale)** |
| 7-8 | Data Integrity | Transactions, complete implementations |
| 8 | Integration | End-to-end testing, documentation |

**Target Release:** v0.6.0 (Early February 2026)

---

## Consequences

### Positive

- ‚úÖ **Enterprise adoption unblocked** - Organizations can deploy with confidence
- ‚úÖ **Millions-scale support** - Neo4j/PostgreSQL unified adapters handle 10M+ nodes
- ‚úÖ **Operational simplicity** - Single database for graph+vector (unified mode)
- ‚úÖ **Transactional consistency** - Unified storage = single transaction boundary
- ‚úÖ **Operational visibility** - Metrics, tracing, health checks for production support
- ‚úÖ **Security posture** - Authentication, authorization, input validation
- ‚úÖ **Reliability** - Retry, circuit breakers, proper error handling
- ‚úÖ **Developer experience preserved** - Defaults remain simple for local development

### Negative

- ‚ö†Ô∏è **Increased complexity** - More configuration options, more code paths
- ‚ö†Ô∏è **Testing burden** - Must test both development and production modes
- ‚ö†Ô∏è **Documentation** - Significant docs update required
- ‚ö†Ô∏è **Performance overhead** - Metrics, tracing add ~5% latency in production mode

### Neutral

- ‚ÑπÔ∏è **Optional dependencies** - Production features are opt-in, not increasing JAR size for development
- ‚ÑπÔ∏è **Backward compatible** - Existing configurations continue working

---

## Related Decisions

- **IDR-001:** Unified Storage Adapter Support - Unified storage remains priority, production hardening enables it
- **ADR-002:** Knowledge Model Design - Core model unchanged
- **Future IDR-005:** Kubernetes Deployment Patterns - Will build on observability foundation

---

## References

- [Resilience4j Documentation](https://resilience4j.readme.io/)
- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [Micrometer Metrics](https://micrometer.io/docs)
- [OpenTelemetry for Java](https://opentelemetry.io/docs/instrumentation/java/)
- [CEF KNOWN_ISSUES.md](../KNOWN_ISSUES.md) - Current documented issues

---

**Implementation Status:** üü° Proposed (awaiting team review)  
**Target Release:** v0.6.0  
**Breaking Changes:** None  
**Risk Level:** Medium (significant changes but isolated behind feature flags)

---

## Appendix A: Full Issue Inventory

### Critical Issues (Must Fix)

1. No retry mechanisms for external services
2. No circuit breakers
3. No timeouts on external calls
4. JGraphT not thread-safe for concurrent access
5. No authentication/authorization
6. Zero metrics integration
7. Fake health checks (always returns UP)
8. No actuator endpoints
9. Secrets in default configuration
10. No input validation
11. Schema initialization failures silently ignored

### High Priority Issues (Should Fix)

1. Silent error swallowing in indexing
2. Dual persistence race condition
3. No distributed tracing
4. Error message information leakage
5. No rate limiting
6. Blocking calls in reactive chain
7. No transaction management for batch operations
8. Incomplete implementations return null/empty
9. No bounds checking on traversal depth
10. Connection pooling not configured for DuckDB
11. Memory leak risk in graph loading
12. Uncaught exceptions in graph operations
13. No connection pool configuration
14. Inconsistent logging levels

### Medium Priority Issues (Nice to Have)

1. Hardcoded magic numbers
2. Connection leak in DuckDB initialization
3. Resource handling (unclosed InputStreams)
4. Missing schema validation
5. Default passwords in config
6. No input sanitization for LLM
7. Incomplete method implementations

---

## Appendix B: Test Coverage Gap Analysis

### Current Test State (Brutal Assessment)

| Test Category | Files | Coverage | Production Ready? |
|---------------|-------|----------|-------------------|
| Unit Tests | ~5 | Basic CRUD only | ‚ùå NO |
| Integration Tests | ~8 | Happy path only | ‚ùå NO |
| Concurrency Tests | 1 | Writes only, no read/write mix | ‚ùå NO |
| Resilience Tests | 0 | None | ‚ùå NO |
| Security Tests | 0 | None | ‚ùå NO |
| Performance Tests | 0 | None (benchmarks are functional, not perf) | ‚ùå NO |
| Chaos Tests | 0 | None | ‚ùå NO |
| Load Tests | 0 | None | ‚ùå NO |

### Existing Test Issues

#### 1. Concurrency Test is Incomplete
**File:** `InMemoryKnowledgeGraphTest.java` (line 413-438)

```java
@Test
void shouldHandleConcurrentAccess() throws InterruptedException {
    // ONLY tests concurrent WRITES
    // Does NOT test:
    // - Concurrent reads during writes (the actual bug!)
    // - Read consistency during modifications
    // - Edge operations concurrent with node operations
}
```

**Problem:** This test passes but doesn't catch the actual thread-safety bug documented in KNOWN_ISSUES.md.

#### 2. No Error/Failure Path Tests
```java
// Current tests only verify happy paths:
@Test void shouldAddAndFindNode()  // ‚úÖ Happy path
@Test void shouldFindShortestPath()  // ‚úÖ Happy path

// Missing failure tests:
// ‚ùå shouldRetryOnTransientEmbeddingFailure()
// ‚ùå shouldOpenCircuitAfterConsecutiveFailures()
// ‚ùå shouldTimeoutOnSlowEmbeddingService()
// ‚ùå shouldRejectInvalidInput()
```

#### 3. Benchmarks Test Functionality, Not Performance
```java
// BenchmarkBase.java - measures latency but has no:
// - Percentile tracking (p50, p95, p99)
// - Throughput measurement
// - Memory profiling
// - Sustained load testing
```

#### 4. No Testcontainers for Neo4j/PostgreSQL Unified
```java
// Current: Only DuckDB + PostgreSQL (separate)
// Missing: Neo4j testcontainer for unified adapter testing
```

---

## Appendix C: Comprehensive Test Plan for v0.6

### Test Categories Required

```
tests/
‚îú‚îÄ‚îÄ unit/                     # Fast, isolated tests
‚îú‚îÄ‚îÄ integration/              # Component integration
‚îú‚îÄ‚îÄ resilience/               # Retry, circuit breaker, timeout
‚îú‚îÄ‚îÄ concurrency/              # Thread safety, race conditions
‚îú‚îÄ‚îÄ security/                 # Auth, input validation
‚îú‚îÄ‚îÄ performance/              # Latency, throughput, memory
‚îú‚îÄ‚îÄ chaos/                    # Failure injection
‚îú‚îÄ‚îÄ scale/                    # Large dataset tests
‚îî‚îÄ‚îÄ e2e/                      # Full system tests
```

### Phase 1: Resilience Tests (Week 1-2)

#### 1.1 Retry Mechanism Tests

```java
@Nested
@DisplayName("Embedding Service Retry Tests")
class EmbeddingRetryTests {
    
    @Test
    @DisplayName("Should retry on transient failure and succeed")
    void shouldRetryAndSucceed() {
        // Given: Embedding service fails twice, then succeeds
        AtomicInteger callCount = new AtomicInteger(0);
        when(embeddingModel.embed(anyString())).thenAnswer(inv -> {
            if (callCount.incrementAndGet() < 3) {
                throw new RuntimeException("Transient failure");
            }
            return new float[768];
        });
        
        // When
        Mono<float[]> result = embeddingService.embed("test");
        
        // Then
        StepVerifier.create(result)
            .expectNextCount(1)
            .verifyComplete();
        assertThat(callCount.get()).isEqualTo(3);
    }
    
    @Test
    @DisplayName("Should fail after max retries exhausted")
    void shouldFailAfterMaxRetries() {
        // Given: Embedding service always fails
        when(embeddingModel.embed(anyString()))
            .thenThrow(new RuntimeException("Permanent failure"));
        
        // When
        Mono<float[]> result = embeddingService.embed("test");
        
        // Then
        StepVerifier.create(result)
            .expectError(EmbeddingServiceException.class)
            .verify(Duration.ofSeconds(10));
    }
    
    @Test
    @DisplayName("Should use exponential backoff between retries")
    void shouldUseExponentialBackoff() {
        // Given: Service fails, track timing between calls
        List<Long> callTimes = new CopyOnWriteArrayList<>();
        when(embeddingModel.embed(anyString())).thenAnswer(inv -> {
            callTimes.add(System.currentTimeMillis());
            throw new RuntimeException("Fail");
        });
        
        // When
        embeddingService.embed("test").onErrorComplete().block();
        
        // Then: Verify backoff timing (1s, 2s, 4s)
        assertThat(callTimes.get(1) - callTimes.get(0)).isGreaterThan(900);
        assertThat(callTimes.get(2) - callTimes.get(1)).isGreaterThan(1900);
    }
}
```

#### 1.2 Circuit Breaker Tests

```java
@Nested
@DisplayName("Circuit Breaker Tests")
class CircuitBreakerTests {
    
    @Test
    @DisplayName("Should open circuit after consecutive failures")
    void shouldOpenCircuitAfterFailures() {
        // Given: Configure circuit breaker to open after 5 failures
        // When: 5 consecutive failures
        for (int i = 0; i < 5; i++) {
            embeddingService.embed("test").onErrorComplete().block();
        }
        
        // Then: Circuit is OPEN, calls fail fast
        StepVerifier.create(embeddingService.embed("test"))
            .expectError(CircuitBreakerOpenException.class)
            .verify(Duration.ofMillis(100)); // Fast fail, no retry
    }
    
    @Test
    @DisplayName("Should transition to half-open after wait duration")
    void shouldTransitionToHalfOpen() throws InterruptedException {
        // Given: Circuit is open
        openCircuit();
        
        // When: Wait for configured duration (30s in production, 1s in test)
        Thread.sleep(1100);
        
        // Then: Circuit is HALF_OPEN, allows probe request
        when(embeddingModel.embed(anyString())).thenReturn(new float[768]);
        StepVerifier.create(embeddingService.embed("test"))
            .expectNextCount(1)
            .verifyComplete();
    }
    
    @Test
    @DisplayName("Should close circuit after successful probe")
    void shouldCloseCircuitAfterSuccess() {
        // Given: Circuit is half-open
        // When: Successful request
        // Then: Circuit closes, normal operation resumes
    }
    
    @Test
    @DisplayName("Circuit breaker metrics should be exposed")
    void shouldExposeCircuitBreakerMetrics() {
        // Verify Prometheus metrics:
        // - cef_circuit_breaker_state{name="embedding"} 
        // - cef_circuit_breaker_calls_total{name="embedding",outcome="success"}
        // - cef_circuit_breaker_calls_total{name="embedding",outcome="failure"}
    }
}
```

#### 1.3 Timeout Tests

```java
@Nested
@DisplayName("Timeout Tests")
class TimeoutTests {
    
    @Test
    @DisplayName("Should timeout on slow embedding service")
    void shouldTimeoutOnSlowEmbedding() {
        // Given: Embedding takes 60s
        when(embeddingModel.embed(anyString())).thenAnswer(inv -> {
            Thread.sleep(60000);
            return new float[768];
        });
        
        // When: Timeout configured at 30s
        StepVerifier.create(embeddingService.embed("test"))
            .expectError(TimeoutException.class)
            .verify(Duration.ofSeconds(35));
    }
    
    @Test
    @DisplayName("Should not block thread pool on timeout")
    void shouldNotBlockThreadPoolOnTimeout() {
        // Given: Multiple slow requests
        // When: Submit 100 requests with 30s timeout
        List<Mono<float[]>> requests = IntStream.range(0, 100)
            .mapToObj(i -> embeddingService.embed("test" + i))
            .toList();
        
        // Then: All should timeout without exhausting thread pool
        long start = System.currentTimeMillis();
        Flux.merge(requests)
            .onErrorContinue((e, o) -> {})
            .blockLast(Duration.ofSeconds(60));
        long elapsed = System.currentTimeMillis() - start;
        
        // Should complete in ~30s (timeout), not 100*30s (sequential)
        assertThat(elapsed).isLessThan(40000);
    }
}
```

### Phase 2: Concurrency Tests (Week 2-3)

#### 2.1 Thread Safety Tests

```java
@Nested
@DisplayName("Thread Safety Tests")
class ThreadSafetyTests {
    
    @Test
    @DisplayName("Should handle concurrent reads during writes without corruption")
    void shouldHandleConcurrentReadsAndWrites() throws InterruptedException {
        // Given: Pre-populate graph with 1000 nodes
        for (int i = 0; i < 1000; i++) {
            graph.addNode(createNode("Initial" + i));
        }
        
        ExecutorService executor = Executors.newFixedThreadPool(20);
        AtomicInteger readErrors = new AtomicInteger(0);
        AtomicInteger writeErrors = new AtomicInteger(0);
        CountDownLatch latch = new CountDownLatch(20);
        
        // When: 10 writers + 10 readers concurrently
        for (int i = 0; i < 10; i++) {
            final int writerId = i;
            executor.submit(() -> {
                try {
                    for (int j = 0; j < 100; j++) {
                        graph.addNode(createNode("Writer" + writerId + "_" + j));
                        graph.addEdge(createRandomEdge());
                    }
                } catch (Exception e) {
                    writeErrors.incrementAndGet();
                } finally {
                    latch.countDown();
                }
            });
        }
        
        for (int i = 0; i < 10; i++) {
            executor.submit(() -> {
                try {
                    for (int j = 0; j < 100; j++) {
                        // Read operations that previously caused ConcurrentModificationException
                        graph.getEdges(getRandomNodeId());
                        graph.getNeighbors(getRandomNodeId(), 2);
                        graph.findShortestPath(getRandomNodeId(), getRandomNodeId());
                    }
                } catch (ConcurrentModificationException e) {
                    readErrors.incrementAndGet();
                } catch (Exception e) {
                    // Other errors
                } finally {
                    latch.countDown();
                }
            });
        }
        
        latch.await(30, TimeUnit.SECONDS);
        
        // Then: No ConcurrentModificationExceptions
        assertThat(readErrors.get())
            .withFailMessage("Got %d ConcurrentModificationExceptions during reads", readErrors.get())
            .isZero();
        assertThat(writeErrors.get()).isZero();
    }
    
    @Test
    @DisplayName("Should maintain data consistency under concurrent load")
    void shouldMaintainConsistencyUnderLoad() throws InterruptedException {
        // Given: Known initial state
        Node root = createNode("Root");
        graph.addNode(root);
        
        // When: Concurrent modifications
        ExecutorService executor = Executors.newFixedThreadPool(10);
        int operationsPerThread = 1000;
        CountDownLatch latch = new CountDownLatch(10);
        
        for (int i = 0; i < 10; i++) {
            final int threadId = i;
            executor.submit(() -> {
                try {
                    for (int j = 0; j < operationsPerThread; j++) {
                        Node child = createNode("Child_" + threadId + "_" + j);
                        graph.addNode(child);
                        graph.addEdge(createEdge(root.getId(), child.getId(), "HAS", 1.0));
                    }
                } finally {
                    latch.countDown();
                }
            });
        }
        
        latch.await(60, TimeUnit.SECONDS);
        
        // Then: Exactly 10,001 nodes and 10,000 edges
        assertThat(graph.getNodeCount()).isEqualTo(10001);
        assertThat(graph.getEdgeCount()).isEqualTo(10000);
        assertThat(graph.getChildren(root.getId())).hasSize(10000);
    }
}
```

#### 2.2 Race Condition Tests

```java
@Nested
@DisplayName("Race Condition Tests")  
class RaceConditionTests {
    
    @Test
    @DisplayName("Should detect and handle dual persistence inconsistency")
    void shouldHandleDualPersistenceFailure() {
        // Given: DuckDB succeeds, in-memory fails
        doThrow(new RuntimeException("Graph full"))
            .when(inMemoryGraph).addNode(any());
        
        // When: Index a node
        Mono<Node> result = indexer.indexNode(testNode);
        
        // Then: Should rollback DuckDB or flag inconsistency
        StepVerifier.create(result)
            .expectError(DualPersistenceException.class)
            .verify();
        
        // Verify DuckDB was rolled back OR inconsistency is tracked
        assertThat(nodeRepository.findById(testNode.getId()).block()).isNull();
    }
    
    @Test
    @DisplayName("Should handle concurrent embedding for same node")
    void shouldHandleConcurrentEmbeddingForSameNode() throws InterruptedException {
        // Given: Same node submitted twice concurrently
        Node node = createNodeWithContent("Patient John Doe");
        
        CountDownLatch latch = new CountDownLatch(2);
        AtomicReference<Throwable> error = new AtomicReference<>();
        
        // When
        for (int i = 0; i < 2; i++) {
            new Thread(() -> {
                try {
                    indexer.indexNode(node).block();
                } catch (Exception e) {
                    error.set(e);
                } finally {
                    latch.countDown();
                }
            }).start();
        }
        
        latch.await(10, TimeUnit.SECONDS);
        
        // Then: One succeeds, one is idempotent (not duplicate)
        assertThat(error.get()).isNull();
        assertThat(chunkStore.findByLinkedNodeId(node.getId()).collectList().block())
            .hasSize(1); // Not 2!
    }
}
```

### Phase 3: Security Tests (Week 4-5)

```java
@Nested
@DisplayName("Security Tests")
class SecurityTests {
    
    @Test
    @DisplayName("Should reject unauthenticated request in production mode")
    void shouldRejectUnauthenticatedRequest() {
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .bodyValue(validRequest)
            .exchange()
            .expectStatus().isUnauthorized();
    }
    
    @Test
    @DisplayName("Should accept valid JWT token")
    void shouldAcceptValidJwtToken() {
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + validJwtToken)
            .bodyValue(validRequest)
            .exchange()
            .expectStatus().isOk();
    }
    
    @Test
    @DisplayName("Should reject expired JWT token")
    void shouldRejectExpiredToken() {
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + expiredJwtToken)
            .exchange()
            .expectStatus().isUnauthorized();
    }
    
    @Test
    @DisplayName("Should validate input and reject negative topK")
    void shouldRejectNegativeTopK() {
        RetrievalRequest invalid = RetrievalRequest.builder()
            .query("test")
            .topK(-1)  // Invalid
            .build();
        
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + validJwtToken)
            .bodyValue(invalid)
            .exchange()
            .expectStatus().isBadRequest()
            .expectBody()
            .jsonPath("$.errors[0].field").isEqualTo("topK")
            .jsonPath("$.errors[0].message").contains("must be greater than 0");
    }
    
    @Test
    @DisplayName("Should reject query exceeding max length")
    void shouldRejectOversizeQuery() {
        String hugeQuery = "a".repeat(100001);  // > 10KB
        
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + validJwtToken)
            .bodyValue(Map.of("textQuery", hugeQuery))
            .exchange()
            .expectStatus().isBadRequest();
    }
    
    @Test
    @DisplayName("Should not leak internal errors in response")
    void shouldNotLeakInternalErrors() {
        // Given: Force internal error
        doThrow(new SQLException("Connection to db.internal.corp:5432 failed"))
            .when(chunkStore).findTopKSimilar(any(), anyInt());
        
        // When
        WebTestClient.ResponseSpec response = webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + validJwtToken)
            .bodyValue(validRequest)
            .exchange();
        
        // Then: Generic error, no internal details
        response.expectStatus().is5xxServerError()
            .expectBody()
            .jsonPath("$.message").value(msg -> {
                assertThat((String) msg).doesNotContain("db.internal.corp");
                assertThat((String) msg).doesNotContain("SQLException");
                assertThat((String) msg).contains("Reference:");
            });
    }
    
    @Test
    @DisplayName("Should enforce traversal depth limit")
    void shouldEnforceTraversalDepthLimit() {
        RetrievalRequest deepTraversal = RetrievalRequest.builder()
            .query("test")
            .graphQuery(GraphQuery.builder()
                .traversal(TraversalHint.builder().maxDepth(100).build())  // Attack
                .build())
            .build();
        
        webTestClient.post()
            .uri("/api/mcp/invoke")
            .header("Authorization", "Bearer " + validJwtToken)
            .bodyValue(deepTraversal)
            .exchange()
            .expectStatus().isBadRequest()
            .expectBody()
            .jsonPath("$.errors[0].message").contains("maxDepth must be <= 10");
    }
}
```

### Phase 4: Performance & Scale Tests (Week 5-6)

```java
@Nested
@DisplayName("Performance Benchmarks")
@Tag("performance")
class PerformanceTests {
    
    @Test
    @DisplayName("Embedding latency p95 should be < 500ms")
    void embeddingLatencyP95() {
        // Given: 1000 embedding requests
        List<Long> latencies = new ArrayList<>();
        
        for (int i = 0; i < 1000; i++) {
            long start = System.nanoTime();
            embeddingService.embed("Test query " + i).block();
            latencies.add((System.nanoTime() - start) / 1_000_000);
        }
        
        // Then: p95 < 500ms
        Collections.sort(latencies);
        long p95 = latencies.get(949);
        assertThat(p95).isLessThan(500);
    }
    
    @Test
    @DisplayName("Graph traversal should complete in < 100ms for 100K nodes")
    void graphTraversalPerformance() {
        // Given: 100K nodes, 500K edges
        loadLargeGraph(100_000, 500_000);
        
        // When: Multi-hop traversal
        long start = System.nanoTime();
        List<Node> neighbors = graph.getNeighbors(randomNodeId, 3);
        long elapsed = (System.nanoTime() - start) / 1_000_000;
        
        // Then
        assertThat(elapsed).isLessThan(100);
    }
    
    @Test
    @DisplayName("Vector search should complete in < 50ms for 50K chunks")
    void vectorSearchPerformance() {
        // Given: 50K chunks with embeddings
        loadChunks(50_000);
        
        // When
        long start = System.nanoTime();
        List<Chunk> results = chunkStore.findTopKSimilar(queryVector, 10)
            .collectList().block();
        long elapsed = (System.nanoTime() - start) / 1_000_000;
        
        // Then
        assertThat(elapsed).isLessThan(50);
    }
    
    @Test
    @DisplayName("Memory usage should stay under 2GB for 100K nodes")
    void memoryUsageUnderLimit() {
        // Given
        Runtime runtime = Runtime.getRuntime();
        long beforeMB = (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024);
        
        // When: Load 100K nodes
        loadLargeGraph(100_000, 500_000);
        System.gc();
        
        long afterMB = (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024);
        long graphMemoryMB = afterMB - beforeMB;
        
        // Then
        assertThat(graphMemoryMB).isLessThan(2048);
    }
    
    @Test
    @DisplayName("Throughput should exceed 100 requests/second")
    void throughputTest() {
        // Given: Warm up
        for (int i = 0; i < 100; i++) {
            retriever.retrieveContext(smallRequest).block();
        }
        
        // When: Measure throughput
        long start = System.nanoTime();
        int requestCount = 1000;
        
        Flux.range(0, requestCount)
            .flatMap(i -> retriever.retrieveContext(smallRequest), 10)
            .blockLast();
        
        long elapsedMs = (System.nanoTime() - start) / 1_000_000;
        double rps = (requestCount * 1000.0) / elapsedMs;
        
        // Then
        assertThat(rps).isGreaterThan(100);
    }
}
```

### Phase 5: Chaos/Failure Injection Tests (Week 6-7)

```java
@Nested
@DisplayName("Chaos Engineering Tests")
@Tag("chaos")
class ChaosTests {
    
    @Test
    @DisplayName("Should recover from embedding service restart")
    void shouldRecoverFromEmbeddingServiceRestart() {
        // Given: Indexing in progress
        Flux<Node> indexingStream = Flux.range(0, 1000)
            .map(i -> createNode("Node" + i))
            .flatMap(indexer::indexNode, 10);
        
        // When: Kill embedding service mid-stream
        CompletableFuture.runAsync(() -> {
            try {
                Thread.sleep(500);
                stopOllamaContainer();
                Thread.sleep(2000);
                startOllamaContainer();
            } catch (Exception e) {}
        });
        
        // Then: Indexing completes after recovery
        StepVerifier.create(indexingStream.collectList())
            .assertNext(nodes -> {
                assertThat(nodes).hasSize(1000);
                // Some may have failed embeddings (acceptable)
                long withEmbeddings = nodes.stream()
                    .filter(n -> hasEmbedding(n))
                    .count();
                assertThat(withEmbeddings).isGreaterThan(900);
            })
            .verifyComplete();
    }
    
    @Test
    @DisplayName("Should handle database connection pool exhaustion")
    void shouldHandleConnectionPoolExhaustion() {
        // Given: Pool size = 10, submit 100 concurrent requests
        Flux<RetrievalResult> requests = Flux.range(0, 100)
            .flatMap(i -> retriever.retrieveContext(request), 100);
        
        // Then: Should queue, not fail
        StepVerifier.create(requests.collectList())
            .assertNext(results -> assertThat(results).hasSize(100))
            .verifyComplete();
    }
    
    @Test
    @DisplayName("Should survive network partition to vector store")
    void shouldSurviveNetworkPartition() {
        // Given: Simulate network partition
        toxiproxy.getProxy("qdrant").toxics()
            .timeout("partition", ToxicDirection.DOWNSTREAM, 30000);
        
        // When: Query during partition
        Mono<RetrievalResult> result = retriever.retrieveContext(request)
            .timeout(Duration.ofSeconds(35));
        
        // Then: Falls back gracefully (graph-only or cached)
        StepVerifier.create(result)
            .assertNext(r -> {
                assertThat(r.getStrategy()).isIn(
                    RetrievalStrategy.GRAPH_ONLY,
                    RetrievalStrategy.CACHED
                );
            })
            .verifyComplete();
    }
}
```

### Phase 6: Unified Storage Adapter Tests (Week 6-7)

```java
@Nested
@DisplayName("Neo4j Unified Adapter Tests")
@Testcontainers
class Neo4jUnifiedAdapterTests {
    
    @Container
    static Neo4jContainer<?> neo4j = new Neo4jContainer<>("neo4j:5.15-enterprise")
        .withEnv("NEO4J_ACCEPT_LICENSE_AGREEMENT", "yes")
        .withPlugins("apoc");
    
    @Test
    @DisplayName("Should store and retrieve nodes via Cypher")
    void shouldStoreAndRetrieveNodes() {
        // Test Neo4jGraphStore implementation
    }
    
    @Test
    @DisplayName("Should perform vector similarity via native index")
    void shouldPerformVectorSimilarity() {
        // Test Neo4j vector index
    }
    
    @Test
    @DisplayName("Should execute unified hybrid query in single transaction")
    void shouldExecuteUnifiedHybridQuery() {
        // Given: Nodes with embeddings
        // When: Hybrid query (vector + graph traversal)
        // Then: Single Cypher query executed
    }
    
    @Test
    @DisplayName("Should scale to 1M nodes with acceptable latency")
    void shouldScaleToMillionNodes() {
        // Load 1M nodes
        // Verify query latency < 200ms
    }
}

@Nested
@DisplayName("PostgreSQL Unified Adapter Tests")
@Testcontainers
class PostgresUnifiedAdapterTests {
    
    @Container
    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("pgvector/pgvector:pg16")
        .withInitScript("schema-postgresql-unified.sql");
    
    @Test
    @DisplayName("Should traverse graph via recursive CTE")
    void shouldTraverseViaRecursiveCTE() {
        // Test PostgreSQL graph traversal
    }
    
    @Test
    @DisplayName("Should use HNSW index for vector search")
    void shouldUseHNSWIndex() {
        // Verify HNSW index is used (not brute force)
    }
}
```

### Phase 7: Health & Observability Tests (Week 7-8)

```java
@Nested
@DisplayName("Health Check Tests")
class HealthCheckTests {
    
    @Test
    @DisplayName("Health should be DOWN when embedding service unavailable")
    void healthDownWhenEmbeddingUnavailable() {
        // Given: Embedding service stopped
        stopOllamaContainer();
        
        // When
        webTestClient.get()
            .uri("/actuator/health")
            .exchange()
            .expectStatus().is5xxServerError()
            .expectBody()
            .jsonPath("$.status").isEqualTo("DOWN")
            .jsonPath("$.components.embeddingService.status").isEqualTo("DOWN");
    }
    
    @Test
    @DisplayName("Health should be DOWN when database unavailable")
    void healthDownWhenDatabaseUnavailable() {
        // Given: Database stopped
        stopDatabaseContainer();
        
        // When/Then
        webTestClient.get()
            .uri("/actuator/health")
            .exchange()
            .expectStatus().is5xxServerError()
            .expectBody()
            .jsonPath("$.components.db.status").isEqualTo("DOWN");
    }
    
    @Test
    @DisplayName("All metrics should be exposed on /actuator/prometheus")
    void allMetricsExposed() {
        String metrics = webTestClient.get()
            .uri("/actuator/prometheus")
            .exchange()
            .expectStatus().isOk()
            .expectBody(String.class)
            .returnResult()
            .getResponseBody();
        
        // Required metrics
        assertThat(metrics).contains("cef_embedding_duration_seconds");
        assertThat(metrics).contains("cef_retrieval_duration_seconds");
        assertThat(metrics).contains("cef_graph_nodes_total");
        assertThat(metrics).contains("cef_graph_edges_total");
        assertThat(metrics).contains("cef_circuit_breaker_state");
        assertThat(metrics).contains("resilience4j_retry_calls_total");
    }
}
```

---

## Appendix D: Benchmark Requirements for Production Sign-Off

### Mandatory Benchmarks

| Benchmark | Target | Current | Gap |
|-----------|--------|---------|-----|
| Embedding p50 latency | < 100ms | ~200ms | ‚ùå |
| Embedding p95 latency | < 500ms | Unknown | ‚ùå |
| Vector search p50 (50K chunks) | < 20ms | ~50ms | ‚ùå |
| Graph traversal p50 (100K nodes, 3-hop) | < 50ms | Unknown | ‚ùå |
| Hybrid query p50 | < 200ms | ~500ms | ‚ùå |
| Throughput (requests/sec) | > 100 | Unknown | ‚ùå |
| Memory (100K nodes) | < 2GB | ~350MB | ‚úÖ |
| Concurrent users | 100+ | Unknown | ‚ùå |
| Cold start time | < 30s | Unknown | ‚ùå |
| Recovery time after failure | < 60s | Unknown | ‚ùå |

### Benchmark Report Format

Each v0.6 release must include:

```markdown
# CEF v0.6 Performance Benchmark Report

## Environment
- Hardware: c5.2xlarge (8 vCPU, 16GB RAM)
- OS: Ubuntu 22.04
- Java: OpenJDK 17.0.9
- Database: PostgreSQL 16 + pgvector 0.5.1
- Embedding: Ollama nomic-embed-text (768d)

## Results

### Latency (p50/p95/p99)
| Operation | p50 | p95 | p99 | Target |
|-----------|-----|-----|-----|--------|
| Embedding | 85ms | 210ms | 450ms | ‚úÖ |
| Vector Search | 12ms | 35ms | 78ms | ‚úÖ |
| Graph Traversal | 22ms | 45ms | 89ms | ‚úÖ |
| Hybrid Query | 145ms | 320ms | 580ms | ‚úÖ |

### Throughput
| Scenario | RPS | Target |
|----------|-----|--------|
| Read-only | 450 | ‚úÖ |
| Mixed (80/20) | 280 | ‚úÖ |
| Write-heavy | 120 | ‚úÖ |

### Scale
| Dataset Size | Memory | Query p95 |
|--------------|--------|-----------|
| 10K nodes | 120MB | 15ms |
| 100K nodes | 890MB | 45ms |
| 1M nodes (Neo4j) | N/A | 180ms |

### Resilience
| Scenario | Recovery Time | Data Loss |
|----------|---------------|-----------|
| Embedding restart | 8s | 0 |
| Database failover | 15s | 0 |
| OOM kill | 25s | 0 |
```

---

## Appendix E: CI/CD Integration

### Required CI Jobs

```yaml
# .github/workflows/production-readiness.yml
name: Production Readiness

on:
  push:
    branches: [main, release/*]
  pull_request:
    branches: [main]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run unit tests
        run: mvn test -Dtest="*Test" -DexcludedGroups="integration,performance,chaos"

  integration-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: pgvector/pgvector:pg16
      ollama:
        image: ollama/ollama:latest
    steps:
      - name: Run integration tests
        run: mvn test -Dgroups="integration"

  security-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Run security tests
        run: mvn test -Dtest="*SecurityTest*"
      - name: OWASP dependency check
        run: mvn org.owasp:dependency-check-maven:check

  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Run performance benchmarks
        run: mvn test -Dgroups="performance" -DargLine="-Xmx4g"
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-report
          path: target/benchmark-report.md

  chaos-tests:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/release/*'
    steps:
      - name: Run chaos tests
        run: mvn test -Dgroups="chaos"
```

### Release Gate Requirements

Before v0.6 release:

- [ ] All unit tests pass (100%)
- [ ] All integration tests pass (100%)
- [ ] Security tests pass (100%)
- [ ] Performance benchmarks meet targets
- [ ] Chaos tests pass (90%+ recovery)
- [ ] No critical/high CVEs in dependencies
- [ ] Code coverage > 80%
- [ ] Mutation testing score > 70%
