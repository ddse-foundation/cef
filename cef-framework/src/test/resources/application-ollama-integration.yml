# Test Configuration for Ollama LLM Integration Tests
# Activate with: mvn test -Dollama.integration=true

spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        enabled: true
        options:
          model: qwq:32b
          temperature: 0.7
      embedding:
        enabled: true
        options:
          model: nomic-embed-text:latest

cef:
  vector:
    store: duckdb
    dimension: 768
  embedding:
    batch-size: 10
    dimensions: 768

logging:
  level:
    org.ddse.ml.cef: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.ai.ollama: TRACE
